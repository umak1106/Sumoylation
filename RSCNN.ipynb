{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzhLPV3Glb8QwgPbC9jpD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umak1106/Sumoylation/blob/main/RSCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "from itertools import cycle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os, re, sys\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Save forecast results\n",
        "def save_predict_result(data, output):\n",
        "    with open(output, 'w') as f:\n",
        "        if len(data)>1:\n",
        "            for i in range(len(data)):\n",
        "                f.write('# result for fold %d\\n' % (i + 1))\n",
        "                for j in range(len(data[i])):\n",
        "                    f.write('%d\\t%s\\n' % (data[i][j][0], data[i][j][2]))\n",
        "        else:\n",
        "            for i in range(len(data)):\n",
        "                f.write('# result for predict\\n')\n",
        "                for j in range(len(data[i])):\n",
        "                    f.write('%d\\t%s\\n' % (data[i][j][0], data[i][j][2]))\n",
        "        f.close()\n",
        "    return None\n",
        "\n",
        "# Plot the ROC curve and return the AUC value\n",
        "def plot_roc_curve(data, output, label_column=0, score_column=2):\n",
        "    datasize = len(data)\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    fprArray = []\n",
        "    tprArray = []\n",
        "    thresholdsArray = []\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    for i in range(len(data)):\n",
        "        fpr, tpr, thresholds = roc_curve(data[i][:, label_column], data[i][:, score_column])\n",
        "        fprArray.append(fpr)\n",
        "        tprArray.append(tpr)\n",
        "        thresholdsArray.append(thresholds)\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "        tprs[-1][0] = 0.0\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        aucs.append(roc_auc)\n",
        "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blueviolet', 'deeppink'])\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    for i, color in zip(range(len(fprArray)), colors):\n",
        "        if datasize>1:\n",
        "            plt.plot(fprArray[i], tprArray[i], lw=1, alpha=0.7, color=color,\n",
        "                     label='ROC fold %d (AUC = %0.4f)' % (i + 1, aucs[i]))\n",
        "        else:\n",
        "            plt.plot(fprArray[i], tprArray[i], lw=1, alpha=0.7, color=color,\n",
        "                     label='ROC (AUC = %0.4f)' %aucs[i])\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "             label='Random', alpha=.8)\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    # Calculate the standard deviation\n",
        "    std_auc = np.std(aucs)\n",
        "    if datasize>1:\n",
        "        plt.plot(mean_fpr, mean_tpr, color='blue',\n",
        "                 label=r'Mean ROC (AUC = %0.4f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
        "                 lw=2, alpha=.9)\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    if datasize>1:\n",
        "        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                         label=r'$\\pm$ 1 std. dev.')\n",
        "    plt.xlim([0, 1.0])\n",
        "    plt.ylim([0, 1.0])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig(output)\n",
        "    plt.close(0)\n",
        "    return mean_auc, aucs\n",
        "\n",
        "# Plot the PRC curve and return the PRC value\n",
        "def plot_prc_curve(data, output, label_column=0, score_column=2):\n",
        "    datasize = len(data)\n",
        "    precisions = []\n",
        "    aucs = []\n",
        "    recall_array = []\n",
        "    precision_array = []\n",
        "    mean_recall = np.linspace(0, 1, 100)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        precision, recall, _ = precision_recall_curve(data[i][:, label_column], data[i][:, score_column])\n",
        "        recall_array.append(recall)\n",
        "        precision_array.append(precision)\n",
        "        precisions.append(np.interp(mean_recall, recall[::-1], precision[::-1])[::-1])\n",
        "        roc_auc = auc(recall, precision)\n",
        "        aucs.append(roc_auc)\n",
        "\n",
        "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blueviolet', 'deeppink', 'cyan'])\n",
        "    # ROC plot for CV\n",
        "    fig = plt.figure(figsize=(7,7))\n",
        "    for i, color in zip(range(len(recall_array)), colors):\n",
        "        if datasize>1:\n",
        "            plt.plot(recall_array[i], precision_array[i], lw=1, alpha=0.7, color=color,\n",
        "                     label='PRC fold %d (AUPRC = %0.4f)' % (i + 1, aucs[i]))\n",
        "        else:\n",
        "            plt.plot(recall_array[i], precision_array[i], lw=1, alpha=0.7, color=color,\n",
        "                     label='PRC (AUPRC = %0.4f)' %aucs[i])\n",
        "    mean_precision = np.mean(precisions, axis=0)\n",
        "    mean_recall = mean_recall[::-1]\n",
        "    mean_auc = auc(mean_recall, mean_precision)\n",
        "    std_auc = np.std(aucs)\n",
        "\n",
        "    if datasize>1:\n",
        "        plt.plot(mean_recall, mean_precision, color='blue',\n",
        "                 label=r'Mean PRC (AUPRC = %0.4f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
        "                 lw=2, alpha=.9)\n",
        "    std_precision = np.std(precisions, axis=0)\n",
        "    precision_upper = np.minimum(mean_precision + std_precision, 1)\n",
        "    precision_lower = np.maximum(mean_precision - std_precision, 0)\n",
        "    if datasize>1:\n",
        "        plt.fill_between(mean_recall, precision_lower, precision_upper, color='grey', alpha=.2,\n",
        "                         label=r'$\\pm$ 1 std. dev.')\n",
        "    plt.xlim([0, 1.0])\n",
        "    plt.ylim([0, 1.0])\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.savefig(output)\n",
        "    plt.close(0)\n",
        "    return mean_auc, aucs\n",
        "\n",
        "# Calculate and save performance metrics\n",
        "def calculate_metrics(labels, scores, cutoff=0.5, po_label=1):\n",
        "    my_metrics = {\n",
        "        'SN': 'NA',\n",
        "        'SP': 'NA',\n",
        "        'ACC': 'NA',\n",
        "        'MCC': 'NA',\n",
        "        'Recall': 'NA',\n",
        "        'Precision': 'NA',\n",
        "        'F1-score': 'NA',\n",
        "        'Cutoff': cutoff,\n",
        "    }\n",
        "\n",
        "    tp, tn, fp, fn = 0, 0, 0, 0\n",
        "    for i in range(len(scores)):\n",
        "        if labels[i] == po_label:\n",
        "            if scores[i] >= cutoff:\n",
        "                tp = tp + 1\n",
        "            else:\n",
        "                fn = fn + 1\n",
        "        else:\n",
        "            if scores[i] < cutoff:\n",
        "                tn = tn + 1\n",
        "            else:\n",
        "                fp = fp + 1\n",
        "\n",
        "    my_metrics['SN'] = tp / (tp + fn) if (tp + fn) != 0 else 'NA'\n",
        "    my_metrics['SP'] = tn / (fp + tn) if (fp + tn) != 0 else 'NA'\n",
        "    my_metrics['ACC'] = (tp + tn) / (tp + fn + tn + fp)\n",
        "    my_metrics['MCC'] = (tp * tn - fp * fn) / np.math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) if (\n",
        "                                                                                                                     tp + fp) * (\n",
        "                                                                                                                     tp + fn) * (\n",
        "                                                                                                                     tn + fp) * (\n",
        "                                                                                                                     tn + fn) != 0 else 'NA'\n",
        "    my_metrics['Precision'] = tp / (tp + fp) if (tp + fp) != 0 else 'NA'\n",
        "    my_metrics['Recall'] = my_metrics['SN']\n",
        "    my_metrics['F1-score'] = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 'NA'\n",
        "    return my_metrics\n",
        "\n",
        "def calculate_metrics_list(data, label_column=0, score_column=2, cutoff=0.5, po_label=1):\n",
        "    metrics_list = []\n",
        "    for i in data:\n",
        "        metrics_list.append(calculate_metrics(i[:, label_column], i[:, score_column], cutoff=cutoff, po_label=po_label))\n",
        "    if len(metrics_list) == 1:\n",
        "        return metrics_list\n",
        "    else:\n",
        "        mean_dict = {}\n",
        "        std_dict = {}\n",
        "        keys = metrics_list[0].keys()\n",
        "        for i in keys:\n",
        "            mean_list = []\n",
        "            for metric in metrics_list:\n",
        "                mean_list.append(metric[i])\n",
        "            mean_dict[i] = np.array(mean_list).sum() / len(metrics_list)\n",
        "            std_dict[i] = np.array(mean_list).std()\n",
        "        metrics_list.append(mean_dict)\n",
        "        metrics_list.append(std_dict)\n",
        "        return metrics_list\n",
        "\n",
        "def save_prediction_metrics_list(metrics_list, output):\n",
        "    if len(metrics_list) == 1:\n",
        "        with open(output, 'w') as f:\n",
        "            f.write('Result')\n",
        "            for keys in metrics_list[0]:\n",
        "                f.write('\\t%s' % keys)\n",
        "            f.write('\\n')\n",
        "            for i in range(len(metrics_list)):\n",
        "                f.write('value')\n",
        "                for keys in metrics_list[i]:\n",
        "                    f.write('\\t%s' % metrics_list[i][keys])\n",
        "                f.write('\\n')\n",
        "            f.close()\n",
        "    else:\n",
        "        with open(output, 'w') as f:\n",
        "            f.write('Fold')\n",
        "            for keys in metrics_list[0]:\n",
        "                f.write('\\t%s' % keys)\n",
        "            f.write('\\n')\n",
        "            for i in range(len(metrics_list)):\n",
        "                if i <= len(metrics_list)-3:\n",
        "                    f.write('%d' % (i + 1))\n",
        "                elif i == len(metrics_list)-2:\n",
        "                    f.write('mean')\n",
        "                else:\n",
        "                    f.write('std')\n",
        "                for keys in metrics_list[i]:\n",
        "                    f.write('\\t%s' % metrics_list[i][keys])\n",
        "                f.write('\\n')\n",
        "            f.close()\n",
        "    return None\n",
        "\n",
        "# Fixed SP value, computing performance\n",
        "def fixed_sp_calculate_metrics_list(data, cutoffs, label_column=0, score_column=1, po_label=1):\n",
        "    metrics_list = []\n",
        "    for index,i in enumerate(data):\n",
        "        metrics_list.append(calculate_metrics(i[:, label_column], i[:, score_column], cutoff=cutoffs[index], po_label=po_label))\n",
        "    if len(metrics_list) == 1:\n",
        "        return metrics_list\n",
        "    else:\n",
        "        mean_dict = {}\n",
        "        std_dict = {}\n",
        "        keys = metrics_list[0].keys()\n",
        "        for i in keys:\n",
        "            mean_list = []\n",
        "            for metric in metrics_list:\n",
        "                mean_list.append(metric[i])\n",
        "            mean_dict[i] = np.array(mean_list).sum() / len(metrics_list)\n",
        "            std_dict[i] = np.array(mean_list).std()\n",
        "        metrics_list.append(mean_dict)\n",
        "        metrics_list.append(std_dict)\n",
        "        return metrics_list"
      ],
      "metadata": {
        "id": "LmeNZCapr-yS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os,sys,re\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from numpy import *\n",
        "\n",
        "def Binary(filepath, CodeType):\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for aa in sequence:\n",
        "            singlecode = []\n",
        "            for aa1 in AA:\n",
        "                tag = 1 if aa == aa1 else 0\n",
        "                singlecode.append(tag)\n",
        "            code.append(singlecode)\n",
        "        encodings.append(code)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "def EAAC(filepath, CodeType, windows=5):\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for j in range(len(sequence)):\n",
        "            singlecode = []\n",
        "            if j < len(sequence) and j + windows <= len(sequence):\n",
        "                count = Counter(re.sub('X', '', sequence[j:j + windows]))\n",
        "                for key in count:\n",
        "                    count[key] = count[key] / windows\n",
        "                for aa in AA:\n",
        "                    singlecode.append(count[aa])\n",
        "                code.append(singlecode)\n",
        "        encodings.append(code)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "def Binary_of_bigram(filepath):\n",
        "    aaPairs = []\n",
        "    encodings = []\n",
        "    for i in itertools.product('ACDEFGHIKLMNPQRSTVWY', repeat=2):\n",
        "        aaPairs.append(''.join(i))\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for index in range(len(sequence)-1):\n",
        "            singercode = np.zeros(len(aaPairs))\n",
        "            pattern = '' + sequence[index] + sequence[index+1]\n",
        "            if pattern in aaPairs:\n",
        "            \t    singercode[aaPairs.index(pattern)] = 1\n",
        "            code.append(singercode)\n",
        "        encodings.append(code)\n",
        "    return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "\n",
        "def BLOSUM62(filepath,CodeType):\n",
        "    blosum62 = {\n",
        "        'A': [4, -1, -2, -2, 0, -1, -1, 0, -2, -1, -1, -1, -1, -2, -1, 1, 0, -3, -2, 0],  # A\n",
        "        'R': [-1, 5, 0, -2, -3, 1, 0, -2, 0, -3, -2, 2, -1, -3, -2, -1, -1, -3, -2, -3],  # R\n",
        "        'N': [-2, 0, 6, 1, -3, 0, 0, 0, 1, -3, -3, 0, -2, -3, -2, 1, 0, -4, -2, -3],  # N\n",
        "        'D': [-2, -2, 1, 6, -3, 0, 2, -1, -1, -3, -4, -1, -3, -3, -1, 0, -1, -4, -3, -3],  # D\n",
        "        'C': [0, -3, -3, -3, 9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1],  # C\n",
        "        'Q': [-1, 1, 0, 0, -3, 5, 2, -2, 0, -3, -2, 1, 0, -3, -1, 0, -1, -2, -1, -2],  # Q\n",
        "        'E': [-1, 0, 0, 2, -4, 2, 5, -2, 0, -3, -3, 1, -2, -3, -1, 0, -1, -3, -2, -2],  # E\n",
        "        'G': [0, -2, 0, -1, -3, -2, -2, 6, -2, -4, -4, -2, -3, -3, -2, 0, -2, -2, -3, -3],  # G\n",
        "        'H': [-2, 0, 1, -1, -3, 0, 0, -2, 8, -3, -3, -1, -2, -1, -2, -1, -2, -2, 2, -3],  # H\n",
        "        'I': [-1, -3, -3, -3, -1, -3, -3, -4, -3, 4, 2, -3, 1, 0, -3, -2, -1, -3, -1, 3],  # I\n",
        "        'L': [-1, -2, -3, -4, -1, -2, -3, -4, -3, 2, 4, -2, 2, 0, -3, -2, -1, -2, -1, 1],  # L\n",
        "        'K': [-1, 2, 0, -1, -3, 1, 1, -2, -1, -3, -2, 5, -1, -3, -1, 0, -1, -3, -2, -2],  # K\n",
        "        'M': [-1, -1, -2, -3, -1, 0, -2, -3, -2, 1, 2, -1, 5, 0, -2, -1, -1, -1, -1, 1],  # M\n",
        "        'F': [-2, -3, -3, -3, -2, -3, -3, -3, -1, 0, 0, -3, 0, 6, -4, -2, -2, 1, 3, -1],  # F\n",
        "        'P': [-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4, 7, -1, -1, -4, -3, -2],  # P\n",
        "        'S': [1, -1, 1, 0, -1, 0, 0, 0, -1, -2, -2, 0, -1, -2, -1, 4, 1, -3, -2, -2],  # S\n",
        "        'T': [0, -1, 0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1, 1, 5, -2, -2, 0],  # T\n",
        "        'W': [-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1, 1, -4, -3, -2, 11, 2, -3],  # W\n",
        "        'Y': [-2, -2, -2, -3, -2, -1, -2, -3, 2, -1, -1, -2, -1, 3, -3, -2, -2, 2, 7, -1],  # Y\n",
        "        'V': [0, -3, -3, -3, -1, -2, -2, -3, -3, 3, 1, -2, 1, -1, -2, -2, 0, -3, -1, 4],  # V\n",
        "        'X': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # X\n",
        "    }\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for aa in sequence:\n",
        "            singlecode = []\n",
        "            if aa in blosum62.keys():\n",
        "                singlecode = singlecode + blosum62[aa]\n",
        "            else:\n",
        "                singlecode = singlecode + blosum62['-']\n",
        "            code.append(singlecode)\n",
        "        encodings.append(code)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "def ZScale(filepath, CodeType):\n",
        "    zscale = {\n",
        "        'A': [0.24, -2.32, 0.60, -0.14, 1.30],  # A\n",
        "        'C': [0.84, -1.67, 3.71, 0.18, -2.65],  # C\n",
        "        'D': [3.98, 0.93, 1.93, -2.46, 0.75],  # D\n",
        "        'E': [3.11, 0.26, -0.11, -0.34, -0.25],  # E\n",
        "        'F': [-4.22, 1.94, 1.06, 0.54, -0.62],  # F\n",
        "        'G': [2.05, -4.06, 0.36, -0.82, -0.38],  # G\n",
        "        'H': [2.47, 1.95, 0.26, 3.90, 0.09],  # H\n",
        "        'I': [-3.89, -1.73, -1.71, -0.84, 0.26],  # I\n",
        "        'K': [2.29, 0.89, -2.49, 1.49, 0.31],  # K\n",
        "        'L': [-4.28, -1.30, -1.49, -0.72, 0.84],  # L\n",
        "        'M': [-2.85, -0.22, 0.47, 1.94, -0.98],  # M\n",
        "        'N': [3.05, 1.62, 1.04, -1.15, 1.61],  # N\n",
        "        'P': [-1.66, 0.27, 1.84, 0.70, 2.00],  # P\n",
        "        'Q': [1.75, 0.50, -1.44, -1.34, 0.66],  # Q\n",
        "        'R': [3.52, 2.50, -3.50, 1.99, -0.17],  # R\n",
        "        'S': [2.39, -1.07, 1.15, -1.39, 0.67],  # S\n",
        "        'T': [0.75, -2.18, -1.12, -1.46, -0.40],  # T\n",
        "        'V': [-2.59, -2.64, -1.54, -0.85, -0.02],  # V\n",
        "        'W': [-4.36, 3.94, 0.59, 3.44, -1.59],  # W\n",
        "        'Y': [-2.54, 2.44, 0.43, 0.04, -1.47],  # Y\n",
        "        'X': [0.00, 0.00, 0.00, 0.00, 0.00],  # X\n",
        "    }\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for aa in sequence:\n",
        "            singlecode = []\n",
        "            if aa in zscale.keys():\n",
        "                singlecode = singlecode + zscale[aa]\n",
        "            else:\n",
        "                singlecode = singlecode + zscale['-']\n",
        "            code.append(singlecode)\n",
        "        encodings.append(code)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "def EGAAC(filepath, CodeType, window = 5):\n",
        "    group = {\n",
        "        'alphaticr': 'GAVLMI',\n",
        "        'aromatic': 'FYW',\n",
        "        'postivecharger': 'KRH',\n",
        "        'negativecharger': 'DE',\n",
        "        'uncharger': 'STCPNQ'\n",
        "    }\n",
        "    groupKey = group.keys()\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for j in range(len(sequence)):\n",
        "            if j + window <= len(sequence):\n",
        "                singlecode = []\n",
        "                count = Counter(re.sub('X', '', sequence[j:j + window]))\n",
        "                myDict = {}\n",
        "                for key in groupKey:\n",
        "                    for aa in group[key]:\n",
        "                        myDict[key] = myDict.get(key, 0) + count[aa]\n",
        "                for key in groupKey:\n",
        "                    singlecode.append(myDict[key] / window)\n",
        "                code.append(singlecode)\n",
        "        encodings.append(code)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "def getPSSM(filepath, CodeType):\n",
        "    encodings = []\n",
        "    label = []\n",
        "    files = os.listdir(filepath) # 读入文件夹\n",
        "    sorted_files = sorted(files,key = lambda i:int(re.findall(r'_(\\d+)-',i)[0]))\n",
        "    for file in sorted_files:\n",
        "        label.append(int(file[file.find('.')-1]))\n",
        "        pssm = []\n",
        "        with open(os.path.join(filepath, file)) as f:\n",
        "            lines = f.readlines()[3:38]\n",
        "            pssm = np.array([line.split()[2:22] for line in lines], dtype=int)\n",
        "            f.close()\n",
        "            encodings.append(pssm)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "\n",
        "def AAindex(filepath, CodeType):\n",
        "    AA = 'ARNDCQEGHILKMFPSTWYV'\n",
        "    fileAAindex = r'D:\\jupyter\\DeepSUMO-master\\Utils\\data\\Sort_AAindex.txt'\n",
        "    with open(fileAAindex) as f:\n",
        "        records = f.readlines()[1:15]\n",
        "    AAindex = []\n",
        "    AAindexName = []\n",
        "    for i in records:\n",
        "        AAindex.append(i.rstrip().split()[1:] if i.rstrip() != '' else None)\n",
        "        AAindexName.append(i.rstrip().split()[0] if i.rstrip() != '' else None)\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for j in sequence:\n",
        "            single_code = []\n",
        "            for k in AAindexName:\n",
        "                if j in AA:\n",
        "                    value = AAindex[AAindexName.index(k)][AA.index(j)]\n",
        "                else:\n",
        "                    value = 0\n",
        "                single_code.append(value)\n",
        "            code.append(single_code)\n",
        "        encodings.append(code)\n",
        "    if CodeType == 1:\n",
        "        return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "    else:\n",
        "        return np.array(encodings).astype(np.float64).reshape(len(encodings),-1), np.array(label).astype(np.float64)\n",
        "\n",
        "def CKSAAP(filepath, gap = 0):\n",
        "    AA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "    aaPairs = []\n",
        "    patten = re.compile('X|U|-|_')\n",
        "    for aa1 in AA:\n",
        "        for aa2 in AA:\n",
        "            aaPairs.append(aa1 + aa2)\n",
        "    encodings = []\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = []\n",
        "        for g in range(gap + 1):\n",
        "            myDict = {}\n",
        "            for pair in aaPairs:\n",
        "                myDict[pair] = 0\n",
        "            sum = 0\n",
        "            for index1 in range(len(sequence)):\n",
        "                index2 = index1 + g + 1\n",
        "                if index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[\n",
        "                    index2] in AA:\n",
        "                    myDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "                    sum = sum + 1\n",
        "            for pair in aaPairs:\n",
        "                code.append(myDict[pair] / sum)\n",
        "        encodings.append(code)\n",
        "    return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "\n",
        "# Construct four sets of features (0, 1 notation) based on the properties of amino acids that appear at -2, -1 and +1, +2\n",
        "def Statistics_property(filepath):\n",
        "    dataframe = pd.read_csv(filepath)\n",
        "    label = list(dataframe['Label'])\n",
        "    sequences = list(dataframe['Sequence'])\n",
        "    encodings = []\n",
        "    middle = len(sequences[0])//2\n",
        "    positive_cahrge = 'DE'\n",
        "    negative_charge = 'RKH'\n",
        "    charge = 'DERKH'\n",
        "    Hydrophobic = 'AFGILPVWY'\n",
        "    type1 = 'ILV'\n",
        "    type2 = 'AFMPW'\n",
        "    type3 = 'GY'\n",
        "\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        code = zeros(11)\n",
        "        if sequence[middle-2] in positive_cahrge:\n",
        "            code[0] = 1\n",
        "        else:\n",
        "            if sequence[middle-2] in negative_charge:\n",
        "                code[1] = 1\n",
        "        if sequence[middle-1] in type1:\n",
        "            code[5] = 1\n",
        "        else:\n",
        "            if sequence[middle-1] in type2:\n",
        "                code[4] = 1\n",
        "            else:\n",
        "                if sequence[middle-1] in type3:\n",
        "                    code[3] = 1\n",
        "                else:\n",
        "                    code[2] = 1\n",
        "        if sequence[middle-1] in charge:\n",
        "            code[6] = 1\n",
        "        if sequence[middle+1] in Hydrophobic:\n",
        "            code[7] = 1\n",
        "        if sequence[middle+1] in charge:\n",
        "            code[8] = 1\n",
        "        if sequence[middle+2] in positive_cahrge:\n",
        "            code[9] = 1\n",
        "        else:\n",
        "            if sequence[middle+2] in negative_charge:\n",
        "                code[10] = 1\n",
        "\n",
        "        encodings.append(code)\n",
        "    return np.array(encodings).astype(np.float64), np.array(label).astype(np.float64)\n",
        "\n",
        "def getSequence(train_fastas):\n",
        "    pos_list = []\n",
        "    neg_list = []\n",
        "    sequences = list(train_fastas['Sequence'])\n",
        "    labels = list(train_fastas['Label'])\n",
        "    for s, l in zip(sequences, labels):\n",
        "        if l==1:\n",
        "            pos_list.append(s)\n",
        "        else:\n",
        "            neg_list.append(s)\n",
        "    return pos_list, neg_list\n",
        "\n",
        "# Determine whether it is a natural amino acid, use 'X' to represent all other amino acids, and construct a frequency matrix\n",
        "def replace_no_native_amino_acid(lists):\n",
        "    native_amino_acid = ('A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "                         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y',)\n",
        "    frequency_array = zeros((21, len(lists[0])))\n",
        "    flag = 1\n",
        "    for site in range(len(lists)):\n",
        "        for i in range(len(lists[0])):\n",
        "            for j in range(len(native_amino_acid)):\n",
        "                if lists[site][i] == native_amino_acid[j]:\n",
        "                    frequency_array[j][i] = frequency_array[j][i] + 1\n",
        "                    flag = 0\n",
        "                    break\n",
        "            if flag != 0:\n",
        "                frequency_array[20][i] = frequency_array[20][i]+1\n",
        "            flag = 1\n",
        "\n",
        "    length = len(lists)\n",
        "    for i in range(len(frequency_array)):\n",
        "        for j in range(len(frequency_array[0])):\n",
        "            frequency_array[i][j] =frequency_array[i][j]/length\n",
        "\n",
        "    return frequency_array\n",
        "\n",
        "# Subtract the negative sample frequency from the positive sample frequency to get the overall sample frequency\n",
        "def result_frequency_matrix(positive_matrix, negative_matrix):\n",
        "    result_matrix = zeros((len(positive_matrix), len(positive_matrix[0])))\n",
        "    for i in range(len(positive_matrix)):\n",
        "        for j in range(len(positive_matrix[0])):\n",
        "            result_matrix[i][j] = positive_matrix[i][j] - negative_matrix[i][j]\n",
        "    return result_matrix\n",
        "\n",
        "\n",
        "# Convert ordinal representation to frequency representation or entropy representation\n",
        "def to_site(lists, frequency_array):\n",
        "    full_frequency_array = []\n",
        "    for i in range(len(lists)):\n",
        "        position = int(lists[i])\n",
        "        full_frequency_array.append(frequency_array[position-1][i])\n",
        "    return full_frequency_array\n",
        "\n",
        "#Convert amino acid sequence to ordinal representation\n",
        "def number_encoding(peptide):\n",
        "    native_amino_acid = ('A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
        "                         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y',)\n",
        "    numlists = zeros(len(peptide))\n",
        "    flag = 1\n",
        "    for i in range(len(peptide)):\n",
        "        for j in range(len(native_amino_acid)):\n",
        "            if peptide[i] == native_amino_acid[j]:\n",
        "                numlists[i] = j+1\n",
        "                flag = 0\n",
        "                break\n",
        "        if flag != 0:\n",
        "            numlists[i] = 21\n",
        "        flag = 1\n",
        "\n",
        "    return numlists\n",
        "\n",
        "def PSAAP(trainpath, testpath = None):\n",
        "    traindf = pd.read_csv(trainpath)\n",
        "\n",
        "    psiteList, nsiteList = getSequence(traindf)\n",
        "    positive_frequency_matrix = replace_no_native_amino_acid(psiteList)\n",
        "    negative_frequency_matrix = replace_no_native_amino_acid(nsiteList)\n",
        "    frequency_matrix = result_frequency_matrix(positive_frequency_matrix, negative_frequency_matrix)\n",
        "\n",
        "    train_encodings = []\n",
        "    train_label = list(traindf['Label'])\n",
        "    sequences = list(traindf['Sequence'])\n",
        "    for i in sequences:\n",
        "        sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "        number_seq = number_encoding(sequence)\n",
        "        code = to_site(number_seq, frequency_matrix)\n",
        "        train_encodings.append(code)\n",
        "    if testpath:\n",
        "        testdf = pd.read_csv(testpath)\n",
        "        test_encodings = []\n",
        "        test_label = list(testdf['Label'])\n",
        "        sequences1 = list(testdf['Sequence'])\n",
        "        for i in sequences1:\n",
        "            sequence = re.sub('[^ACDEFGHIKLMNPQRSTVWYX]', 'X', ''.join(i).upper())\n",
        "            number_seq = number_encoding(sequence)\n",
        "            code = to_site(number_seq, frequency_matrix)\n",
        "            test_encodings.append(code)\n",
        "        return np.array(train_encodings).astype(np.float64), np.array(train_label).astype(np.float64), np.array(test_encodings).astype(np.float64), np.array(test_label).astype(np.float64)\n",
        "\n",
        "    return np.array(train_encodings).astype(np.float64), np.array(train_label).astype(np.float64)"
      ],
      "metadata": {
        "id": "3GnG7XVosR77"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,re\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential, losses, optimizers\n",
        "import pandas as pd\n",
        "from tensorflow.keras import backend as K\n",
        "from collections import Counter\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import KFold, train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "from itertools import cycle\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "def save_result(cv_res, ind_res, outPath, codename):\n",
        "    mkdir(outPath)\n",
        "    out = os.path.join(outPath, codename.lower())\n",
        "    save_predict_result(cv_res, out + '_pre_cv.txt')\n",
        "    cv_meanauc, cv_auc = plot_roc_curve(cv_res, out + '_roc_cv.png', label_column=0, score_column=2)\n",
        "    cv_meanprc, cv_prc = plot_prc_curve(cv_res, out + '_prc_cv.png', label_column=0, score_column=2)\n",
        "    cv_metrics = calculate_metrics_list(cv_res, label_column=0, score_column=2, cutoff=0.5, po_label=1)\n",
        "    save_prediction_metrics_list(cv_metrics, out + '_metrics_cv.txt')\n",
        "    save_predict_result(ind_res, out + '_pre_ind.txt')\n",
        "    ind_meanauc, ind_auc = plot_roc_curve(ind_res, out + '_roc_ind.png', label_column=0, score_column=2)\n",
        "    ind_meanprc, ind_prc = plot_prc_curve(ind_res, out + '_prc_ind.png', label_column=0, score_column=2)\n",
        "    ind_metrics = calculate_metrics_list(ind_res, label_column=0, score_column=2, cutoff=0.5, po_label=1)\n",
        "    save_prediction_metrics_list(ind_metrics, out + '_metrics_ind.txt')\n",
        "    return None\n",
        "\n",
        "# Create folder\n",
        "def mkdir(path):\n",
        "    path=path.strip()\n",
        "    path=path.rstrip(\"\\\\\")\n",
        "    # Check if the path exists\n",
        "    isExists=os.path.exists(path)\n",
        "    if not isExists:\n",
        "        # Create the directory if it doesn't exist\n",
        "        os.makedirs(path)\n",
        "    else:\n",
        "        # Do not create directory if it exists\n",
        "        pass\n",
        "\n",
        "def res_net_block(input_data, filters, strides=1):\n",
        "    x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same')(input_data)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Conv1D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if strides != 1:\n",
        "        downsample = layers.Conv1D(filters, kernel_size=1, strides=strides)(input_data)\n",
        "    else:\n",
        "        downsample = input_data\n",
        "    x = layers.Add()([x, downsample])\n",
        "    output = layers.Activation('relu')(x)\n",
        "\n",
        "    return output\n",
        "\n",
        "# CNN-based classifiers\n",
        "def CNNbasic(Encode):\n",
        "    inputs = tf.keras.Input(shape=(Encode.shape[1], Encode.shape[2]))\n",
        "\n",
        "    x = layers.Conv1D(128, kernel_size=3)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool1D(pool_size=2, strides=1, padding='same')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, kernel_size=3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool1D(pool_size=2, strides=1, padding='same')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dense(64, activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
        "    output = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
        "    DeepSUMO = Model(inputs=[inputs], outputs=[output], name=\"DeepSUMO\")\n",
        "    DeepSUMO.summary()\n",
        "    DeepSUMO.compile(optimizer=optimizers.Adam(),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'],\n",
        "                  experimental_run_tf_function=False)\n",
        "    return DeepSUMO"
      ],
      "metadata": {
        "id": "CvUnNsiOwLZk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "trainfilepath =  'five_fold_cross_validation.csv'\n",
        "testfilepath = 'independent.csv'"
      ],
      "metadata": {
        "id": "tOk-jXIfwXsk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZScale1, y = ZScale(trainfilepath,1)\n",
        "zscale_test, y_test = ZScale(testfilepath, 1)"
      ],
      "metadata": {
        "id": "3GVpYLD1wdQS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ZScale1.shape)\n",
        "print(zscale_test.shape)\n",
        "print(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhCm-PVJyiNE",
        "outputId": "904add43-0845-4e1e-d7f0-d77d0e0c975d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(67090, 39, 5)\n",
            "(7456, 39, 5)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The residual structure layered CNN architecture (RSCNN)\n",
        "def RSCNN(Encode):\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(Encode.shape[1], Encode.shape[2]))\n",
        "    x = layers.Conv1D(128, kernel_size=3)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool1D(pool_size=2, strides=1, padding='same')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = res_net_block(x, 128)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = res_net_block(x, 128)\n",
        "    x = layers.MaxPool1D(2)(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.Dense(64, activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
        "\n",
        "    output = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
        "    DeepSUMO = Model(inputs=[inputs1], outputs=[output], name=\"DeepSUMO\")\n",
        "    DeepSUMO.summary()\n",
        "    DeepSUMO.compile(optimizer=optimizers.Adam(),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'],\n",
        "                  experimental_run_tf_function=False)\n",
        "    return DeepSUMO"
      ],
      "metadata": {
        "id": "h4JKS-78xDXU"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}